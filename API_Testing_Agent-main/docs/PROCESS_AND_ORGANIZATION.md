# ACMS API Testing Agent - Complete Process & Organization Guide

## ğŸ“‹ Table of Contents
1. [System Architecture](#system-architecture)
2. [Where Is Your Agent](#where-is-your-agent)
3. [Complete Process Flow](#complete-process-flow)
4. [Folder Organization](#folder-organization)
5. [File Purpose Reference](#file-purpose-reference)
6. [Data Flow Diagram](#data-flow-diagram)

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACMS API Testing Agent System                     â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Input Files    â”‚      â”‚  Agent Engine   â”‚      â”‚   Output   â”‚  â”‚
â”‚  â”‚   (Specs)        â”‚      â”‚  (Llama3/AI)    â”‚      â”‚   Files    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                         â”‚                      â”‚         â”‚
â”‚  â€¢ Constitution.md â”€â”€â”€â”€â”€â”€> 1. Generate Tests â”€â”€â”€â”€â”€â”€> test_*.py      â”‚
â”‚  â€¢ spec.md                 2. Generate Mock Data    mock_data.json   â”‚
â”‚  â€¢ plan.md                 3. Run Pytest           test_results.json â”‚
â”‚                            4. Validate Results     reports (HTML/MD) â”‚
â”‚                            5. Generate Reports                       â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Where Is Your Agent?

### **AGENT LOCATION**

**File:** `run_agent.py`  
**Type:** Main CLI orchestrator and entry point  
**Location:** Root of `API-testing-agent_penguinalpha/` folder  
**Purpose:** Controls the entire workflow

### **AGENT COMPONENTS**

| Component | File | Purpose |
|-----------|------|---------|
| **Core Agent** | `run_agent.py` | CLI interface & workflow orchestration |
| **Mock Data Generator** | `src/mock_data.py` | Generates realistic test data |
| **Test Runner** | `src/test_runner.py` | Executes pytest and parses results |
| **Validators** | `src/validators.py` | Validates API responses |
| **Report Generator** | `src/report_generator.py` | Creates HTML/JSON/MD reports |
| **LLM Integration** | `src/ollama_agent.py` | Connects to Llama3/Ollama |
| **Configuration** | `src/config.py` | Settings and configuration |
| **Spec Parser** | `src/spec_parser.py` | Parses API specifications |
| **Story Parser** | `src/story_parser.py` | Parses user stories |
| **Code Generator** | `src/code_generator.py` | Generates test code templates |

### **AGENT LOCATION IN CODE**

```python
# Entry point to run the agent:
python run_agent.py [command] [options]

# Commands:
python run_agent.py check                              # Check prerequisites
python run_agent.py generate --resource agents         # Generate tests
python run_agent.py run --pattern test_agents          # Run tests
python run_agent.py full --resource agents             # Complete workflow
```

---

## Complete Process Flow

### **PHASE 1: PREREQUISITES CHECK** âœ“

```
START
  â†“
Check Ollama Connection
  â”œâ”€ Connects to localhost:11434
  â””â”€ Verifies LLM service is running
  â†“
Check Llama3 Model
  â”œâ”€ Confirms model is installed
  â””â”€ Verifies model is available
  â†“
Check Configuration Files
  â”œâ”€ Constitution file (.specify/memory/constitution.md)
  â”œâ”€ Specification file (specs/main/spec.md)
  â””â”€ Plan file (specs/main/plan.md)
  â†“
Check pytest Installation
  â””â”€ Ensures testing framework is available
  â†“
OUTPUT: âœ“ All prerequisites met!
```

**Command:**
```bash
python run_agent.py check
```

**What Happens:**
- Verifies all system dependencies
- Checks if Ollama/Llama3 is running
- Validates input specification files exist
- Ensures pytest is installed

---

### **PHASE 2: TEST GENERATION** ğŸ§ª

```
START
  â†“
â”Œâ”€ GENERATE MOCK DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  1. Create Mock Agents                  â”‚
â”‚     â”œâ”€ Name: Auto-generated            â”‚
â”‚     â”œâ”€ Email: Realistic                â”‚
â”‚     â”œâ”€ Status: Active/Inactive         â”‚
â”‚     â””â”€ Commission Tier: 1-5            â”‚
â”‚                                          â”‚
â”‚  2. Create Mock Policies                â”‚
â”‚     â”œâ”€ Policy Names: Coverage types    â”‚
â”‚     â”œâ”€ Premiums: Realistic amounts     â”‚
â”‚     â””â”€ Effective Dates: Date ranges    â”‚
â”‚                                          â”‚
â”‚  3. Create Mock Commissions             â”‚
â”‚     â”œâ”€ Agent-Policy links             â”‚
â”‚     â”œâ”€ Calculated amounts             â”‚
â”‚     â””â”€ Status tracking                â”‚
â”‚                                          â”‚
â”‚  4. Create Mock Payments                â”‚
â”‚     â”œâ”€ Agent payments                 â”‚
â”‚     â”œâ”€ Payment amounts                â”‚
â”‚     â””â”€ Payment dates                  â”‚
â”‚                                          â”‚
â”‚  OUTPUT: mock_data.json (in generated_tests/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€ GENERATE TEST CODE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  1. Read specification file             â”‚
â”‚  2. Read constitution (optional)        â”‚
â”‚  3. Send to Llama3 AI                  â”‚
â”‚     â”œâ”€ Prompt with API requirements   â”‚
â”‚     â”œâ”€ Include user stories           â”‚
â”‚     â”œâ”€ Define test scenarios          â”‚
â”‚     â””â”€ Specify test types             â”‚
â”‚                                          â”‚
â”‚  4. Llama3 generates:                  â”‚
â”‚     â”œâ”€ Happy path tests               â”‚
â”‚     â”œâ”€ Edge case tests                â”‚
â”‚     â”œâ”€ Error scenario tests           â”‚
â”‚     â”œâ”€ Security tests                 â”‚
â”‚     â””â”€ Integration tests              â”‚
â”‚                                          â”‚
â”‚  OUTPUT: test_[resource]_generated.py
â”‚          (in generated_tests/tests/python/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
OUTPUT: âœ“ Generation complete!
```

**Command:**
```bash
python run_agent.py generate --resource agents --mock-agents 5
```

**What Happens:**
1. Generates 5 mock agents + related data
2. Sends API spec to Llama3
3. Llama3 creates comprehensive test code
4. Saves generated tests to file

**Generated Files:**
- `generated_tests/mock_data.json` - Mock test data
- `generated_tests/tests/python/test_[resource]_generated.py` - Generated test code

---

### **PHASE 3: TEST EXECUTION** â–¶ï¸

```
START
  â†“
â”Œâ”€ FIND TEST FILES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Search for: **/test_*.py               â”‚
â”‚  Location: generated_tests/tests/       â”‚
â”‚  Found: 1 test file                    â”‚
â”‚         test_agents_generated.py        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€ RUN PYTEST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Command:                               â”‚
â”‚  pytest -v --tb=short --timeout=300     â”‚
â”‚          generated_tests/tests/python/  â”‚
â”‚          test_agents_generated.py       â”‚
â”‚                                          â”‚
â”‚  Pytest:                                â”‚
â”‚  â”œâ”€ Collects tests                     â”‚
â”‚  â”œâ”€ Runs each test                     â”‚
â”‚  â”œâ”€ Measures duration                  â”‚
â”‚  â”œâ”€ Captures errors                    â”‚
â”‚  â””â”€ Generates output                   â”‚
â”‚                                          â”‚
â”‚  Output includes:                       â”‚
â”‚  â”œâ”€ test_create_agent_happy_path ... PASSED
â”‚  â”œâ”€ test_get_agent_details ... FAILED
â”‚  â”œâ”€ test_invalid_input ... ERROR
â”‚  â””â”€ Summary: X passed, Y failed        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€ PARSE PYTEST OUTPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Extract:                               â”‚
â”‚  â”œâ”€ Test names                         â”‚
â”‚  â”œâ”€ Test status (PASSED/FAILED/ERROR)  â”‚
â”‚  â”œâ”€ Duration for each test             â”‚
â”‚  â”œâ”€ Error messages                     â”‚
â”‚  â””â”€ Summary statistics                 â”‚
â”‚                                          â”‚
â”‚  Create ExecutionSummary:               â”‚
â”‚  â”œâ”€ total_tests: 16                    â”‚
â”‚  â”œâ”€ passed_tests: 9                    â”‚
â”‚  â”œâ”€ failed_tests: 4                    â”‚
â”‚  â”œâ”€ error_tests: 2                     â”‚
â”‚  â”œâ”€ skipped_tests: 1                   â”‚
â”‚  â””â”€ total_duration_ms: 850             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
OUTPUT: âœ“ Tests completed!
        Passed: 9/16
        Failed: 4/16
        Success Rate: 56.3%
```

**Command:**
```bash
python run_agent.py run --pattern test_agents
```

**What Happens:**
1. Finds all test files matching pattern
2. Executes tests with pytest
3. Captures output and results
4. Parses execution data
5. Calculates statistics

---

### **PHASE 4: REPORT GENERATION** ğŸ“Š

```
START
  â†“
â”Œâ”€ GENERATE HTML REPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Creates: test_report.html              â”‚
â”‚  Location: generated_tests/             â”‚
â”‚                                          â”‚
â”‚  Contains:                              â”‚
â”‚  â”œâ”€ Executive Summary                  â”‚
â”‚  â”‚  â”œâ”€ Total Tests: 16                â”‚
â”‚  â”‚  â”œâ”€ Passed: 9 (56.3%)              â”‚
â”‚  â”‚  â”œâ”€ Failed: 4 (25%)                â”‚
â”‚  â”‚  â””â”€ Errors: 2 (12.5%)              â”‚
â”‚  â”‚                                    â”‚
â”‚  â”œâ”€ Detailed Test Results              â”‚
â”‚  â”‚  â”œâ”€ Test Name                      â”‚
â”‚  â”‚  â”œâ”€ Status (with color)            â”‚
â”‚  â”‚  â”œâ”€ Duration                       â”‚
â”‚  â”‚  â””â”€ Error Messages                 â”‚
â”‚  â”‚                                    â”‚
â”‚  â”œâ”€ Performance Metrics                â”‚
â”‚  â”‚  â”œâ”€ Average Duration               â”‚
â”‚  â”‚  â”œâ”€ Total Time                     â”‚
â”‚  â”‚  â””â”€ Success Rate                   â”‚
â”‚  â”‚                                    â”‚
â”‚  â””â”€ Chart/Visualization               â”‚
â”‚     â”œâ”€ Pass/Fail Pie Chart            â”‚
â”‚     â””â”€ Timeline Graph                 â”‚
â”‚                                          â”‚
â”‚  Styling:                               â”‚
â”‚  â”œâ”€ Professional CSS                  â”‚
â”‚  â”œâ”€ Color-coded status                â”‚
â”‚  â”œâ”€ Responsive design                 â”‚
â”‚  â””â”€ Easy to read tables               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€ GENERATE MARKDOWN REPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Creates: test_report.md                â”‚
â”‚  Location: generated_tests/             â”‚
â”‚                                          â”‚
â”‚  Format:                                â”‚
â”‚  â”œâ”€ Markdown tables                    â”‚
â”‚  â”œâ”€ GitHub-compatible                 â”‚
â”‚  â”œâ”€ Easy to version control           â”‚
â”‚  â””â”€ Embeddable in documentation       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€ GENERATE JSON REPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                          â”‚
â”‚  Creates: test_report.json              â”‚
â”‚  Location: generated_tests/             â”‚
â”‚                                          â”‚
â”‚  Format:                                â”‚
â”‚  â”œâ”€ Machine-readable                  â”‚
â”‚  â”œâ”€ Full test details                 â”‚
â”‚  â”œâ”€ Timestamps                        â”‚
â”‚  â””â”€ Parseable by other tools          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
OUTPUT: âœ“ Reports generated!
        â”œâ”€ HTML: test_report.html
        â”œâ”€ MD: test_report.md
        â””â”€ JSON: test_report.json
```

**Command:**
```bash
python run_agent.py full --resource agents --mock-agents 5
```

**What Happens:**
1. Runs all 4 phases (Prerequisites â†’ Generate â†’ Run â†’ Report)
2. Generates all 3 report types
3. Saves to `generated_tests/` folder

---

## Folder Organization

### **Current Structure (BEFORE REORGANIZATION)**

```
API-testing-agent_penguinalpha/
â”œâ”€â”€ run_agent.py                    [MAIN CLI]
â”œâ”€â”€ your_api_module.py             [MOCK API]
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ setup.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ollama_agent.py           [LLM INTEGRATION]
â”‚   â”œâ”€â”€ config.py                 [CONFIGURATION]
â”‚   â”œâ”€â”€ code_generator.py         [CODE GEN]
â”‚   â”œâ”€â”€ spec_parser.py            [SPEC PARSING]
â”‚   â”œâ”€â”€ story_parser.py           [STORY PARSING]
â”‚   â”œâ”€â”€ test_generator.py         [TEST GEN]
â”‚   â”œâ”€â”€ mock_data.py              [MOCK DATA]
â”‚   â”œâ”€â”€ test_runner.py            [TEST RUNNER]
â”‚   â”œâ”€â”€ validators.py             [VALIDATION]
â”‚   â”œâ”€â”€ report_generator.py       [REPORTING]
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ formatters.py         [FORMATTERS]
â”‚       â”œâ”€â”€ helpers.py            [HELPERS]
â”‚       â””â”€â”€ validators.py         [VALIDATORS]
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ conftest.jinja2
â”‚   â”œâ”€â”€ test_module.jinja2
â”‚   â””â”€â”€ test_specification.jinja2
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_openapi.yaml
â”‚   â””â”€â”€ sample_stories.md
â”œâ”€â”€ generated_tests/              [OUTPUT FOLDER]
â”‚   â”œâ”€â”€ mock_data.json
â”‚   â”œâ”€â”€ test_report.html
â”‚   â”œâ”€â”€ test_report.md
â”‚   â”œâ”€â”€ test_report.json
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”‚   â””â”€â”€ test_agents_generated.py
â”‚   â””â”€â”€ __pycache__/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AI_AGENT_GUIDE.md
â”‚   â”œâ”€â”€ FUNCTIONAL_TESTING_GUIDE.md
â”‚   â”œâ”€â”€ QUICK_REFERENCE.txt
â”‚   â””â”€â”€ QUICK_START.md
â””â”€â”€ [DOCUMENTATION FILES]
    â”œâ”€â”€ README.md
    â”œâ”€â”€ WORKFLOW.html
    â”œâ”€â”€ ANALYSIS.md
    â””â”€â”€ etc.
```

### **RECOMMENDED STRUCTURE (AFTER REORGANIZATION)**

```
API-testing-agent_penguinalpha/
â”‚
â”œâ”€â”€ ğŸ“Œ CORE / ENTRY POINTS
â”‚   â”œâ”€â”€ run_agent.py              [Main CLI entry point]
â”‚   â”œâ”€â”€ setup.py                  [Project setup]
â”‚   â”œâ”€â”€ requirements.txt           [Dependencies]
â”‚   â””â”€â”€ pytest.ini                [Pytest config]
â”‚
â”œâ”€â”€ ğŸ¤– AGENT CORE (src/agent/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py           [Main orchestration logic]
â”‚   â”œâ”€â”€ llm_interface.py          [Llama3/Ollama interface]
â”‚   â””â”€â”€ config.py                 [Configuration management]
â”‚
â”œâ”€â”€ ğŸ“ DATA GENERATION (src/generators/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mock_data_generator.py    [Mock data generation]
â”‚   â”œâ”€â”€ test_code_generator.py    [Test code generation]
â”‚   â”œâ”€â”€ spec_parser.py            [Specification parsing]
â”‚   â””â”€â”€ story_parser.py           [User story parsing]
â”‚
â”œâ”€â”€ ğŸ§ª TEST EXECUTION (src/testing/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_runner.py            [Pytest execution]
â”‚   â”œâ”€â”€ test_executor.py          [Test execution logic]
â”‚   â”œâ”€â”€ pytest_parser.py          [Pytest output parsing]
â”‚   â””â”€â”€ result_collector.py       [Results collection]
â”‚
â”œâ”€â”€ âœ… VALIDATION (src/validation/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validators.py             [Response validators]
â”‚   â”œâ”€â”€ schema_validator.py       [Schema validation]
â”‚   â”œâ”€â”€ business_logic_validator.py
â”‚   â””â”€â”€ security_validator.py     [Security checks]
â”‚
â”œâ”€â”€ ğŸ“Š REPORTING (src/reporting/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ report_generator.py       [Report generation]
â”‚   â”œâ”€â”€ html_reporter.py          [HTML report formatting]
â”‚   â”œâ”€â”€ markdown_reporter.py      [Markdown formatting]
â”‚   â””â”€â”€ json_reporter.py          [JSON formatting]
â”‚
â”œâ”€â”€ ğŸ› ï¸ UTILITIES (src/utils/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ helpers.py                [Helper functions]
â”‚   â”œâ”€â”€ formatters.py             [Output formatters]
â”‚   â”œâ”€â”€ validators.py             [Utility validators]
â”‚   â””â”€â”€ constants.py              [Constants]
â”‚
â”œâ”€â”€ ğŸ“š MOCK API (src/mock_api/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api_client.py             [Mock API client]
â”‚   â””â”€â”€ your_api_module.py        [Mock ACMS API]
â”‚
â”œâ”€â”€ ğŸ“¦ TEMPLATES (templates/)
â”‚   â”œâ”€â”€ conftest.jinja2           [Pytest config template]
â”‚   â”œâ”€â”€ test_module.jinja2        [Test module template]
â”‚   â””â”€â”€ test_specification.jinja2 [Test spec template]
â”‚
â”œâ”€â”€ ğŸ“‹ EXAMPLES (examples/)
â”‚   â”œâ”€â”€ sample_openapi.yaml       [Sample API spec]
â”‚   â”œâ”€â”€ sample_stories.md         [Sample user stories]
â”‚   â””â”€â”€ README.md                 [Examples guide]
â”‚
â”œâ”€â”€ ğŸ“– DOCUMENTATION (docs/)
â”‚   â”œâ”€â”€ README.md                 [Main readme]
â”‚   â”œâ”€â”€ GETTING_STARTED.md        [Setup guide]
â”‚   â”œâ”€â”€ ARCHITECTURE.md           [Architecture]
â”‚   â”œâ”€â”€ API_AGENT_GUIDE.md        [Agent usage]
â”‚   â”œâ”€â”€ PROCESS_AND_ORGANIZATION.md [THIS FILE]
â”‚   â””â”€â”€ TROUBLESHOOTING.md        [Troubleshooting]
â”‚
â””â”€â”€ ğŸ“¤ OUTPUT/RESULTS (generated_tests/)
    â”œâ”€â”€ mock_data/
    â”‚   â”œâ”€â”€ agents.json
    â”‚   â”œâ”€â”€ policies.json
    â”‚   â”œâ”€â”€ commissions.json
    â”‚   â””â”€â”€ payments.json
    â”‚
    â”œâ”€â”€ testcases/
    â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â””â”€â”€ test_agents_generated.py
    â”‚   â”œâ”€â”€ policies/
    â”‚   â”‚   â””â”€â”€ test_policies_generated.py
    â”‚   â””â”€â”€ commissions/
    â”‚       â””â”€â”€ test_commissions_generated.py
    â”‚
    â””â”€â”€ reports/
        â”œâ”€â”€ latest/
        â”‚   â”œâ”€â”€ test_report.html
        â”‚   â”œâ”€â”€ test_report.md
        â”‚   â””â”€â”€ test_report.json
        â”‚
        â””â”€â”€ archive/
            â”œâ”€â”€ test_report_2025-01-10.html
            â””â”€â”€ test_report_2025-01-10.json
```

---

## File Purpose Reference

### **AGENT CORE COMPONENTS**

| File | Purpose | Input | Output |
|------|---------|-------|--------|
| `run_agent.py` | Main CLI orchestrator | CLI args | Command execution |
| `src/agent/llm_interface.py` | Connects to Llama3/Ollama | API specs | Generated test code |
| `src/agent/config.py` | Configuration management | config files | Config objects |

### **DATA GENERATION**

| File | Purpose | Input | Output |
|------|---------|-------|--------|
| `src/generators/mock_data_generator.py` | Creates test data | Scenarios | `mock_data.json` |
| `src/generators/test_code_generator.py` | Generates test code | API specs | Python test file |
| `src/generators/spec_parser.py` | Parses API specs | `spec.md` | Parsed spec object |
| `src/generators/story_parser.py` | Parses user stories | `plan.md` | Story objects |

### **TEST EXECUTION**

| File | Purpose | Input | Output |
|------|---------|-------|--------|
| `src/testing/test_runner.py` | Executes pytest | Test files | Execution results |
| `src/testing/pytest_parser.py` | Parses pytest output | pytest stdout/stderr | TestResult objects |
| `src/testing/result_collector.py` | Collects results | TestResults | ExecutionSummary |

### **REPORTING**

| File | Purpose | Input | Output |
|------|---------|-------|--------|
| `src/reporting/report_generator.py` | Main report coordinator | ExecutionSummary | All report formats |
| `src/reporting/html_reporter.py` | HTML formatting | Summary data | `test_report.html` |
| `src/reporting/markdown_reporter.py` | Markdown formatting | Summary data | `test_report.md` |
| `src/reporting/json_reporter.py` | JSON formatting | Summary data | `test_report.json` |

---

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE DATA FLOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[INPUT PHASE]
     â”‚
     â”œâ”€â†’ constitution.md â”€â”€â†’ â”
     â”œâ”€â†’ spec.md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â””â”€â†’ plan.md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                             â”œâ”€â†’ spec_parser.py â”€â”€â†’ ParsedSpec
                             â”‚
                             â””â”€â†’ story_parser.py â”€â”€â†’ Stories


[GENERATION PHASE]
                        
     ParsedSpec â”€â”
     Stories â”€â”€â”€â”¤â”€â”€â†’ llm_interface.py â”€â”€â†’ Llama3/Ollama â”€â”€â†’ test_code.py
                â”‚
     Config â”€â”€â”€â”€â”˜


     â”Œâ”€â”€â†’ agents scenario â”€â”€â†’ mock_data_generator.py â”€â”€â†’ mock_data.json
     â”‚
     â”œâ”€â”€â†’ policies scenario
     â”‚
     â”œâ”€â”€â†’ commissions scenario
     â”‚
     â””â”€â”€â†’ payments scenario


[EXECUTION PHASE]

     test_code.py â”€â”€â†’ test_runner.py â”€â”€â†’ pytest command â”€â”€â†’ pytest output
                            â”‚                                    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                            pytest_parser.py
                                                  â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â†“                                       â†“
                         TestResult[]                         ExecutionSummary
                              â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â†“


[REPORTING PHASE]

     ExecutionSummary â”€â”€â”¬â”€â”€â†’ html_reporter.py â”€â”€â†’ test_report.html
                        â”œâ”€â”€â†’ markdown_reporter.py â”€â”€â†’ test_report.md
                        â””â”€â”€â†’ json_reporter.py â”€â”€â†’ test_report.json


[OUTPUT PHASE]

     generated_tests/
     â”œâ”€â”€ mock_data.json
     â”œâ”€â”€ testcases/
     â”‚   â””â”€â”€ test_agents_generated.py
     â””â”€â”€ reports/
         â”œâ”€â”€ test_report.html
         â”œâ”€â”€ test_report.md
         â””â”€â”€ test_report.json
```

---

## Quick Command Reference

### **Check Everything**
```bash
python run_agent.py check
```

### **Generate Tests Only**
```bash
python run_agent.py generate --resource agents --mock-agents 5
```

### **Run Tests Only**
```bash
python run_agent.py run --pattern test_agents
```

### **Complete Workflow** (Recommended)
```bash
python run_agent.py full --resource agents --mock-agents 5
```

### **View Reports**
```bash
# HTML Report (open in browser)
start generated_tests/test_report.html

# Markdown Report
cat generated_tests/test_report.md

# JSON Report
type generated_tests/test_report.json
```

---

## Summary

**Where Is The Agent?**
- **Main Entry:** `run_agent.py`
- **Core Logic:** `src/agent/`
- **Data Generation:** `src/generators/`
- **Test Execution:** `src/testing/`
- **Reporting:** `src/reporting/`

**Where Do Tests Get Generated?**
- **Location:** `generated_tests/testcases/[resource]/`
- **File Pattern:** `test_[resource]_generated.py`
- **Generated By:** Llama3 AI via `llm_interface.py`

**Where Do Results Go?**
- **Location:** `generated_tests/reports/`
- **Formats:** HTML, Markdown, JSON
- **Files:** `test_report.[html|md|json]`

**What Operations Happen?**
1. **Prerequisites Check** - Validate system setup
2. **Mock Data Generation** - Create realistic test data
3. **Test Code Generation** - Llama3 generates tests
4. **Test Execution** - Pytest runs generated tests
5. **Results Validation** - Parse and verify results
6. **Report Generation** - Create 3 report formats

---

**Last Updated:** December 3, 2025  
**Version:** 1.0
